1、信息论基础（熵 联合熵 条件熵 信息增益 基尼不纯度）
（1）熵： 表示随机变量不确定性的度量。
（2）联合熵 ：一组变量之间不确定性的衡量手段。
（3）条件熵 ：表示在已知随机变量X的条件下随机变量Y的不确定性。
（4）信息增益 ：表示得知特征X的信息而使得类Y的信息的不确定性减少的程度。
（5）基尼不纯度：是指将来自集合中的某种结果随机应用在集合中，某一数据项
     的预期误差率。在进行决策树编程的时候，可以作为衡量系统混乱程度的标准。
2.决策树的不同分类算法（ID3算法、C4.5、CART分类树）的原理及应用场景
  ID3算法：主要针对属性选择问题。C4.5算法对ID3算法进行了改进。
  CART分类树由两部分组成：（1）决策树生成：基于训练数据集生成决策树，生成的决策树要尽量大；
  （2）决策树剪枝：用验证数据集对已生成的数进行剪枝并选择最优子树，这时用损失函数最小作为剪枝的标准。
3、回归树原理
4、决策树防止过拟合手段  对决策树进行剪枝来简化学到的决策树。决策树的剪枝，往往从已生成的树上剪掉一些叶结点或叶结点以上的子树，
并将其父结点或根结点作为新的叶结点，从而简化生成的决策树。
5、模型评估 随机二次抽样 交叉验证 自助法
6、sklearn参数详解，Python绘制决策树
