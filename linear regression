1.机器学习：积累经验，通过对经验的利用，对新情况做出有效的决策，在计算机上就是说，如何通过计算的手段，利用经验来改善系统自身的性能。
2.有监督学习：训练数据拥有标记信息。
3.无监督学习：训练样本没有标记信息。
4.泛化能力：通过机器学习学得的模型适用于新样本的能力。
5.过拟合：训练出的模型在测试集上表现的非常好，但是不能很好的适应训练集，具有高的方差，应该减少特征变量或者使用正则化方法。
6.欠拟合：模型不能很好的适应测试集，应当添加其它的特征项，改为多项式特征。
7.交叉验证：取一部分数据既用于训练集又用于测试集。
8.线性回归的原理：使用平方项误差，使这个平方误差最小，定义这个误差为代价函数，即线性回归的问题就是求解代价函数的最小值。
9.损失函数：一个函数衡量真实值y好坏的程度。
10.目标函数：用平方损失函数来作为目标函数。
11.梯度下降法：当目标是凸函数时。梯度下降法的解是全局解。梯度下降法的思想是用当前位置负梯度方向作为搜索方向，因为该方向是当前位置的最快下降方向。
12.牛顿法：牛顿法是一种在实数域和复数域上近似求解方程的方法。方法使用函数f (x)的泰勒级数的前面几项来寻找方程f (x) = 0的根。牛顿法最大的特点就在于它的收敛速度很快。
13.拟牛顿法：拟牛顿法的本质思想是改善牛顿法每次需要求解复杂的Hessian矩阵的逆矩阵的缺陷，它使用正定矩阵来近似Hessian矩阵的逆，从而简化了运算的复杂度。拟牛顿法和最速
   下降法一样只要求每一步迭代时知道目标函数的梯度。通过测量梯度的变化，构造一个目标函数的模型使之足以产生超线性收敛性。这类方法大大优于最速下降法，尤其对于困难的问题。
   另外，因为拟牛顿法不需要二阶导数的信息，所以有时比牛顿法更为有效。如今，优化软件中包含了大量的拟牛顿算法用来解决无约束，约束，和大规模的优化问题。
14.线性回归的评估指标：平均绝对误差，平均平方误差。
15.sklearn参数详解
